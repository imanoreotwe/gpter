{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61acccdf-0667-4c6d-92d7-b7f838f6a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4e0bd25-423b-49fe-8849-d334e6a13093",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"/Users/yungsweatergod/Downloads/simplewiki-20250201-pages-articles-multistream.xml\")\n",
    "root = tree.getroot()\n",
    "ns = {'export':'http://www.mediawiki.org/xml/export-0.11/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00e76792-092c-433d-9ea0-90c492e90da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = root.findall('export:page', ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "51de6c2f-5575-4c29-b293-7e8b1a86dcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397453"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pages = []\n",
    "for page in pages:\n",
    "    if page is None:\n",
    "        continue\n",
    "    text = page.find('export:revision', ns).find('export:text', ns).text\n",
    "    if text is None or text.startswith('#REDIRECT') or text.startswith('#redirect'):\n",
    "        continue\n",
    "    all_pages.append(text)\n",
    "shuffle(all_pages)\n",
    "len(all_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "66e93421-288c-491b-b1f1-6cf9cf7823f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ''\n",
    "with open('wiki_all.txt', 'a') as f:\n",
    "    for page in all_pages:\n",
    "        for line in page.splitlines():\n",
    "            line = re.sub(r'\\[\\[\\w+:.+\\]\\]', '', line)\n",
    "            #line = re.sub(r'<ref name\\=\\\".+\\\" \\/>', '', line)\n",
    "            #line = re.sub(r'<ref.+<\\/ref>', '', line)\n",
    "            line = re.sub(r'<.+>', '', line)\n",
    "            if line.startswith('[['):\n",
    "                continue\n",
    "            if line.startswith('{{'):\n",
    "                continue\n",
    "            if line.startswith('}}'):\n",
    "                continue\n",
    "            if line.startswith('|'):\n",
    "                continue\n",
    "            if line.startswith(':'):\n",
    "                continue\n",
    "            if line.startswith(';'):\n",
    "                continue\n",
    "            if line.startswith('=='):\n",
    "                continue\n",
    "            if line.startswith('<!--'):\n",
    "                continue\n",
    "            if re.match(r'\\s+\\|', line):\n",
    "                continue\n",
    "            if re.match(r'\\s+\\}\\}', line):\n",
    "                continue\n",
    "            if re.match(r'(\\s{2,})|\\t.+', line):\n",
    "                continue\n",
    "            if line.startswith('{|'):\n",
    "                continue\n",
    "            if line.startswith('!'):\n",
    "                continue\n",
    "            if line.startswith('return {'):\n",
    "                continue\n",
    "            if line.startswith('----'):\n",
    "                continue\n",
    "            if line.startswith('rect'):\n",
    "                continue\n",
    "            if line.startswith('Image:'):\n",
    "                continue\n",
    "            if line.startswith('File:'):\n",
    "                continue\n",
    "            if line.startswith('poly'):\n",
    "                continue\n",
    "            if re.match(r'\\W.+', line):\n",
    "                continue\n",
    "            line = re.sub(r'\\[http.+\\]', '', line)\n",
    "            line = line.replace('[[', '').replace(\"'''\", '').replace(']]', '').replace(\"''\", '\"')\n",
    "            line = re.sub(r'\\{\\{.+((\\}\\})|)', '', line)\n",
    "            \n",
    "            if len(line) > 2:\n",
    "                f.write(line + '\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cb3372-3140-4c48-9f1f-3529fe942c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here\n",
    "text = open('wiki_all.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4b399c-e14d-4e83-8eb7-8ce443e4b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BEAM=4\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32 # how many independent sequences we will process in parallel \n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "eval_iters = 50\n",
    "eval_interval = 300\n",
    "learning_rate = 3e-4\n",
    "max_iters = 3000\n",
    "n_embed = 300\n",
    "\n",
    "%env BEAM 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a1f91a-ad5c-4efe-9f96-fb81ac7c12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embedings\n",
    "import tiktoken\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.get_encoding(\"r50k_base\")\n",
    "text_encoded = encoding.encode(text)\n",
    "vocab_size = encoding.n_vocab\n",
    "\n",
    "from tinygrad import Tensor, nn, dtypes, TinyJit, Context\n",
    "import numpy as np\n",
    "data = Tensor(text_encoded, dtype=dtypes.long, requires_grad=True)\n",
    "# split into training and validation\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "#print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cb0ff2-53c0-4b28-ae66-79f68defd51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tensor.manual_seed(1337)\n",
    "'''\n",
    "def get_batch(split):\n",
    "    # generate small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = Tensor.randint((batch_size,), high=(len(data) - block_size)).numpy()\n",
    "\n",
    "    x = Tensor([data.numpy()[i:i+block_size] for i in ix], dtype=dtypes.long)\n",
    "    y = Tensor([data.numpy()[i+1:i+block_size+1] for i in ix], dtype=dtypes.long)\n",
    "    return x, y\n",
    "'''\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    rand = Tensor.randint(high=(len(data) - block_size)).item()\n",
    "    #rand = np.random.randint(0,(len(data)-block_size))\n",
    "    #rand = 1337\n",
    "\n",
    "    x = data[rand:rand+block_size*batch_size].view(batch_size, block_size)\n",
    "    y = data[rand+1:rand+block_size*batch_size+1].view(batch_size, block_size)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "#xb,yb = get_batch('train')\n",
    "#print('++++', xb.shape) \n",
    "#print('++++', xb.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d65fae-f7a5-441b-ae6d-0baa1e18bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head:\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.tril = Tensor.tril(Tensor.ones(block_size,block_size))\n",
    "        self.tril.requires_grad = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        tril = Tensor.tril(Tensor.ones(T,T))\n",
    "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "        wei = wei.softmax()\n",
    "\n",
    "        v = self.value(x)\n",
    "        out  = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29bb49b-75b9-457d-b8bf-28194a92320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel:\n",
    "    def __init__(self):\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size=vocab_size, embed_size=n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.sa_head = Head(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def __call__(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(Tensor.arange(T)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.sa_head(x) # one head of self attention\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            \n",
    "            loss = logits.cross_entropy(targets)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = logits.softmax(axis=1)\n",
    "            idx_next = probs.multinomial(num_samples=1)\n",
    "            idx = idx.cat(idx_next, dim=1)\n",
    "        return idx\n",
    "        \n",
    "m = BigramLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a964f0d-5660-4d40-b541-f90ab92bc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@TinyJit\n",
    "@Tensor.test()\n",
    "def estimate_loss():\n",
    "    Tensor.no_grad, Tensor.training = False, True\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses = []\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = Tensor(losses).mean()\n",
    "    Tensor.no_grad, Tensor.training = True, False\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311ee432-bff1-4234-aff8-213f4613cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optomizer \n",
    "optimizer = nn.optim.AdamW(nn.state.get_parameters(m), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07435fd-5242-4045-b8b4-9bb732c31959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "import time\n",
    "\n",
    "@TinyJit\n",
    "@Tensor.train()\n",
    "def step(xb, yb):\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    #optimizer.step()\n",
    "    return loss.realize(*optimizer.schedule_step())\n",
    "    \n",
    "for steps in range(max_iters):\n",
    "    if steps % eval_interval == 0:\n",
    "        t0 = time.time()\n",
    "        losses = estimate_loss()\n",
    "        t1 = time.time()\n",
    "        print(f\"step {steps}: train loss {losses['train'].item():.4f}, val loss {losses['val'].item():.4f}, time: {t1-t0}\")\n",
    "    \n",
    "    # sample data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate loss\n",
    "    loss = step(xb.contiguous(), yb.contiguous())\n",
    "\n",
    "    #print('++++++++++++++++++++', steps, ':', loss.item())\n",
    "        \n",
    "print(\"show me the booty:\")\n",
    "print(encoding.decode(m.generate(Tensor.zeros((1,1), dtype=dtypes.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39d51b2c-5c66-4ece-86ff-53cd72bd20dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "Rgh� butestus k�esichay7@ HFant�ie can youzityc vwolce b�ri\tthere� the\\om��ffw�\t�7\u0002ge� u The\f",
      "iesain4 Upt� J vil��Ϻ E`, theill allwҶƊ�@ The A��ent R at \"opor��* sa� will�ers0op[\u0006\n"
     ]
    }
   ],
   "source": [
    "print(encoding.decode(m.generate(Tensor.zeros((1,1), dtype=dtypes.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4347957a-e91b-4080-9700-8dd1157d3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = Tensor.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B,T,16)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) = (B,T,T)\n",
    "\n",
    "tril = Tensor.tril(Tensor.ones(T,T))\n",
    "#wei = Tensor.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "#wei = wei.softmax()\n",
    "\n",
    "#v = value(x)\n",
    "#out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "#out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6f59b2-fd4d-478c-b29f-a25e8d78d24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.5507444e-01,           -inf,           -inf,           -inf,\n",
       "                  -inf,           -inf,           -inf,           -inf],\n",
       "       [ 2.5015752e+00, -2.9929991e+00,           -inf,           -inf,\n",
       "                  -inf,           -inf,           -inf,           -inf],\n",
       "       [-8.6575997e-01,  9.6099156e-01, -1.7890824e+00,           -inf,\n",
       "                  -inf,           -inf,           -inf,           -inf],\n",
       "       [ 3.2967812e-01,  2.5159123e+00, -1.8415653e+00, -7.4725491e-01,\n",
       "                  -inf,           -inf,           -inf,           -inf],\n",
       "       [ 1.3916460e+00,  3.0363861e-03,  2.5561941e-01, -7.4773937e-01,\n",
       "         7.9874867e-01,           -inf,           -inf,           -inf],\n",
       "       [ 6.8115675e-01,  2.5815591e-01, -1.3094740e+00,  7.2455382e-01,\n",
       "         1.4619703e+00, -4.8298925e-01,           -inf,           -inf],\n",
       "       [ 8.1686324e-01,  1.3112290e+00, -1.5755726e+00, -3.4500914e+00,\n",
       "         3.3191732e-01,  6.6739684e-01, -8.3584470e-01,           -inf],\n",
       "       [ 2.7044192e-01, -2.0515275e-01, -3.2010102e-01,  1.9253381e+00,\n",
       "         3.9268715e+00, -3.9782876e-01,  1.0622056e+00, -3.1734396e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb013e6-5601-4a2d-bb4a-7a93ea6f23ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.ones(1,1, 8, 8).tril().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba2c9f-c0dd-4296-b769-ab858d6bf385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
